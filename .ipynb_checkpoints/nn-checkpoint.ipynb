{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import *\n",
    "from torchnet import meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# %matplotlib notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка данных**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, mini_batch):\n",
    "        self.mini_batch = np.array(mini_batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.mini_batch.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.mini_batch[idx]\n",
    "    \n",
    "    @property\n",
    "    def max(self):\n",
    "        return self.mini_batch.max()\n",
    "        \n",
    "    def peak_index_extractor(self, perc):\n",
    "        '''Extract peak indexes in numpy array higher than threshold'''\n",
    "        \n",
    "        x = self.mini_batch\n",
    "        xmin = x.max() * perc / 100\n",
    "        x = x - xmin\n",
    "        x[x < 0] = 0\n",
    "        peak_storage = []\n",
    "        for i in range(2,len(x)-2):\n",
    "            if (x[i-1] < x[i]) and (x[i+1] < x[i]) and (x[i-2] < x[i]) and (x[i+2] < x[i]):\n",
    "                peak_storage.append(i)\n",
    "        return peak_storage\n",
    "    \n",
    "    def max_len_bw_peaks(self, perc):\n",
    "        '''Calculate maximum lenght between peak neighboorhood'''\n",
    "    \n",
    "        old_x_hat = 0\n",
    "        max_len = 0\n",
    "        for x_hat in self.peak_index_extractor(perc):\n",
    "            if (x_hat - old_x_hat) > max_len: \n",
    "                max_len = x_hat -old_x_hat \n",
    "                v_max = [old_x_hat, x_hat]\n",
    "            old_x_hat = x_hat\n",
    "        return max_len\n",
    "    \n",
    "    def min_len_bw_peaks(self, perc):\n",
    "        '''Calculate minimum lenght between peak neighboorhood'''\n",
    "        \n",
    "        old_x_hat = 0\n",
    "        min_len = 25000\n",
    "        for x_hat in self.peak_index_extractor(perc):\n",
    "            if (x_hat - old_x_hat) < min_len: \n",
    "                min_len = x_hat - old_x_hat \n",
    "                v_min = [old_x_hat, x_hat]\n",
    "            old_x_hat = x_hat\n",
    "        return min_len\n",
    "    \n",
    "    def avg_len_bw_peaks(self, perc):\n",
    "        '''Calculate average lenght between peak neighboorhood'''\n",
    "\n",
    "        old_x_hat = 0\n",
    "        avg_len = 0\n",
    "        cnt = 0\n",
    "        for x_hat in self.peak_index_extractor(perc):\n",
    "            avg_len += (x_hat - old_x_hat)\n",
    "            old_x_hat = x_hat\n",
    "            cnt += 1\n",
    "        if cnt == 0:\n",
    "            return 0\n",
    "        return avg_len / cnt\n",
    "    \n",
    "    @property\n",
    "    def peak_exist(self):\n",
    "        peak_list = self.peak_index_extractor(0)\n",
    "        if peak_list == []:\n",
    "            return 0\n",
    "        return 1\n",
    "    \n",
    "    def find_nullable_mini_batch(self, batches):\n",
    "        offset = 1\n",
    "        for mini_batch in reversed(batches):\n",
    "            if mini_batch[-1] == 1:\n",
    "                return offset\n",
    "            offset += 1\n",
    "        return offset\n",
    "            \n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "        '''Extract features from given time buffer'''\n",
    "        '''Total features = 19'''\n",
    "        \n",
    "        data_features = np.array([np.average(self.mini_batch)])\n",
    "        data_features = np.append(data_features, self.mini_batch.max())\n",
    "        \n",
    "        data_features = np.append(data_features, len(self.peak_index_extractor(0)))\n",
    "        data_features = np.append(data_features, self.min_len_bw_peaks(0))\n",
    "        data_features = np.append(data_features, self.max_len_bw_peaks(0))\n",
    "        data_features = np.append(data_features, self.avg_len_bw_peaks(0))\n",
    "        \n",
    "        data_features = np.append(data_features, len(self.peak_index_extractor(10)))\n",
    "        data_features = np.append(data_features, self.min_len_bw_peaks(10))\n",
    "        data_features = np.append(data_features, self.max_len_bw_peaks(10))\n",
    "        data_features = np.append(data_features, self.avg_len_bw_peaks(10))\n",
    "        \n",
    "        data_features = np.append(data_features, len(self.peak_index_extractor(50)))\n",
    "        data_features = np.append(data_features, self.min_len_bw_peaks(50))\n",
    "        data_features = np.append(data_features, self.max_len_bw_peaks(50))\n",
    "        data_features = np.append(data_features, self.avg_len_bw_peaks(50))\n",
    "        \n",
    "        data_features = np.append(data_features, len(self.peak_index_extractor(90)))\n",
    "        data_features = np.append(data_features, self.min_len_bw_peaks(90))\n",
    "        data_features = np.append(data_features, self.max_len_bw_peaks(90))\n",
    "        data_features = np.append(data_features, self.avg_len_bw_peaks(90))\n",
    "        \n",
    "        data_features = np.append(data_features, self.peak_exist)\n",
    "        return data_features\n",
    "    \n",
    "    def additional_features(self, batches):\n",
    "        '''Extract features that is depends on previous mini_batches'''\n",
    "        '''Total features = 14'''\n",
    "        data_features = np.array([])\n",
    "        if len(batches) > 4:   \n",
    "            data_features = np.array([self.find_nullable_mini_batch(batches)])\n",
    "\n",
    "            data_features = np.append(data_features, batches[-1][6])\n",
    "            data_features = np.append(data_features, batches[-1][10])\n",
    "            data_features = np.append(data_features, batches[-1][14])\n",
    "            data_features = np.append(data_features, batches[-1][15])\n",
    "\n",
    "            data_features = np.append(data_features, batches[-2][6])\n",
    "            data_features = np.append(data_features, batches[-2][10])\n",
    "            data_features = np.append(data_features, batches[-2][14])\n",
    "            data_features = np.append(data_features, batches[-2][15])\n",
    "\n",
    "            data_features = np.append(data_features, batches[-3][6])\n",
    "            data_features = np.append(data_features, batches[-3][10])\n",
    "            data_features = np.append(data_features, batches[-3][14])\n",
    "            data_features = np.append(data_features, batches[-3][15])\n",
    "\n",
    "            data_features = np.append(data_features, batches[-4][6])\n",
    "        else:\n",
    "            data_features = np.zeros(14)\n",
    "        return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataLoader:\n",
    "    def __init__(self, ms=1000, std_size=2):\n",
    "        self.std_size = std_size\n",
    "        self.ms = ms\n",
    "        self.dataset_location = \"./data\"\n",
    "        self.dataset = None\n",
    "        self.alpha_dataset = np.array([])\n",
    "        self.beta_dataset = np.array([])\n",
    "        self.background_dataset = np.array([])\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.X.shape\n",
    "        \n",
    "    def read_file(self, i, j):\n",
    "        '''Получим входные вектора'''\n",
    "        \n",
    "        f = open('./data/%s_%s.txt' %(i,j))\n",
    "        data = []\n",
    "        for line in f:\n",
    "            data.append(float(line))\n",
    "        data = np.array(data)\n",
    "        return data\n",
    "    \n",
    "    def share_data(self, data, ms):\n",
    "        '''Разделим выборку на батчи с интервалов ms (мс)'''\n",
    "        \n",
    "        ms = 10 * ms  // 4\n",
    "        shared_data = []\n",
    "        for iter in range(len(data)//ms):\n",
    "            mini_batch = Batch(data[iter*ms:(iter+1)*ms])\n",
    "            shared_data.append(mini_batch)\n",
    "        return shared_data\n",
    "    \n",
    "    def normalize(self, x, mean, std):\n",
    "        '''Normalize data'''\n",
    "        x_max = 5.0 - mean\n",
    "        x = (x - mean - self.std_size*std) / x_max\n",
    "        x[x < 0] = 0\n",
    "        return x\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        '''Загрузим датасет'''\n",
    "        \n",
    "        for i in tqdm(range(1, 9)):\n",
    "            self.background_dataset = np.concatenate((self.background_dataset, self.read_file(i,1)), axis=0)\n",
    "            self.alpha_dataset = np.concatenate((self.alpha_dataset, self.read_file(i,2)), axis=0)\n",
    "            self.beta_dataset = np.concatenate((self.beta_dataset, self.read_file(i,3)), axis=0)\n",
    "         \n",
    "        mean, std = self.background_dataset.mean(), self.background_dataset.std()\n",
    "        \n",
    "        self.background_dataset = self.normalize(self.background_dataset, mean, std)\n",
    "        self.alpha_dataset = self.normalize(self.alpha_dataset, mean, std)\n",
    "        self.beta_dataset = self.normalize(self.beta_dataset, mean, std)\n",
    "        \n",
    "        self.background_dataset = self.share_data(self.background_dataset, self.ms)\n",
    "        self.alpha_dataset = self.share_data(self.alpha_dataset, self.ms)\n",
    "        self.beta_dataset = self.share_data(self.beta_dataset, self.ms) \n",
    "    \n",
    "    def extract_feature_map(self, dataset):\n",
    "        '''Extract feature map from given dataset'''\n",
    "        \n",
    "        feature_map = []\n",
    "        additional_feature_map = []\n",
    "        for data in dataset:\n",
    "            feature_map.append(data.features)\n",
    "            additional_feature_map.append(data.additional_features(feature_map))\n",
    "        feature_map = np.array(feature_map)\n",
    "        additional_feature_map = np.array(additional_feature_map)\n",
    "        return np.concatenate((feature_map, additional_feature_map), axis=1)\n",
    "    \n",
    "    def generate_inputs_labels(self):\n",
    "        '''Generate inputs and labels for given datasets'''\n",
    "        \n",
    "        alpha_inputs = self.extract_feature_map(self.alpha_dataset)\n",
    "        beta_inputs = self.extract_feature_map(self.beta_dataset)\n",
    "        back_inputs = self.extract_feature_map(self.background_dataset)\n",
    "        \n",
    "        alpha_labels = np.array([1 for x in alpha_inputs])\n",
    "        beta_labels = np.array([2 for x in beta_inputs])\n",
    "        back_labels = np.array([0 for x in back_inputs])\n",
    "        \n",
    "        print (alpha_inputs.shape, beta_inputs.shape, back_inputs.shape)\n",
    "        print (alpha_labels.shape, beta_labels.shape, back_labels.shape)\n",
    "        \n",
    "        self.X = np.concatenate((alpha_inputs, beta_inputs, back_inputs), axis=0)\n",
    "        self.Y = np.concatenate((alpha_labels, beta_labels, back_labels), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим кастомный датасет**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadiatonDataset(Dataset): \n",
    "    def __init__(self, x, y=None):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.labels is not None:\n",
    "            return data, label\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построение модели**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBias(nn.Module):\n",
    "    def __init__(self, output_features=15, bias=True):\n",
    "        super(SigmoidBias, self).__init__()\n",
    "        if bias:\n",
    "            uniform = 0.1*(1-2*torch.rand(output_features))\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = torch.sigmoid(input)\n",
    "        if self.bias is not None:\n",
    "            output = output + self.bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential( \\\n",
    "                                nn.Linear(input_features, 20),\n",
    "                                nn.Linear(20, 10),\n",
    "                                nn.Linear(10, output_features),\n",
    "#                                 SigmoidBias(output_features)\n",
    "                                )\n",
    "\n",
    "    def forward(self, input): \n",
    "        x = self.seq(input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение модели**\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(s_epoch,n_epoch,lr):\n",
    "    '''Only raw data'''\n",
    "    net.train(True)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    for epoch in tqdm(range(s_epoch,n_epoch)):  \n",
    "        running_corrects = 0\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs.float()).cuda(), Variable(labels).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        loss_data.append(running_loss)\n",
    "        corrects.append(running_corrects/len(trainloader.dataset))\n",
    "    print (\"Epoch %s, train accuracy %4s and loss %4s\" %(epoch+1,running_corrects/len(trainloader.dataset),running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_test():\n",
    "    net.train(False)\n",
    "    classes = ('background', 'alpha', 'beta')\n",
    "    class_correct = list(0. for i in range(3))\n",
    "    class_total = list(0. for i in range(3))\n",
    "    \n",
    "    confusion_matrix = meter.ConfusionMeter(3)\n",
    "    \n",
    "    running_corrects=0\n",
    "    running_loss=0\n",
    "    y_hat = []\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(Variable(inputs.float(), volatile=True).cuda())\n",
    "\n",
    "        loss = criterion(outputs, Variable(labels, volatile=True).cuda())\n",
    "        running_loss += loss.data[0]\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_corrects += torch.sum(preds.cpu() == labels)\n",
    "\n",
    "        y_hat.append(outputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted.cpu().numpy() == labels.numpy()).squeeze()\n",
    "        for i in range(c.size):\n",
    "            label = labels.numpy()[i]\n",
    "            class_correct[label] += c[i]\n",
    "            class_total[label] += 1 \n",
    "        confusion_matrix.add(predicted, torch.LongTensor(labels))\n",
    "    print (\"\\nTest accuracy %4s and loss %4s\" %(running_corrects/len(testloader.dataset),running_loss))\n",
    "\n",
    "    for i in range(3):\n",
    "        print('%4s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    class_total[i]\n",
    "    print (\"Confusion matrix:\\n\",confusion_matrix.conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Соединим все вместе**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533, 33) (533, 33) (533, 33)\n",
      "(533,) (533,) (533,)\n",
      "CPU times: user 45.5 s, sys: 36 ms, total: 45.6 s\n",
      "Wall time: 45.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_dataset = MyDataLoader(3000, 2)\n",
    "my_dataset.load_dataset()\n",
    "my_dataset.generate_inputs_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1119, 480)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(my_dataset.X, my_dataset.Y, test_size=0.3, random_state=42)\n",
    "\n",
    "train_dataset = RadiatonDataset(X_train, y_train)\n",
    "test_dataset = RadiatonDataset(X_test, y_test)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_features=33,output_features=3).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_data = []\n",
    "corrects = []\n",
    "\n",
    "lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 29.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, train accuracy 0.6085790884718498 and loss 50.46900397539139\n",
      "\n",
      "Test accuracy 0.6229166666666667 and loss 43.00311779975891\n",
      "background : 84 %\n",
      "alpha : 14 %\n",
      "beta : 93 %\n",
      "Confusion matrix:\n",
      " [[141   1  25]\n",
      " [ 36  25 109]\n",
      " [  5   5 133]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(0,100,lr)\n",
    "check_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:12<00:00, 31.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, train accuracy 0.6586237712243074 and loss 23.100738644599915\n",
      "\n",
      "Test accuracy 0.6541666666666667 and loss 11.29217916727066\n",
      "background : 77 %\n",
      "alpha : 29 %\n",
      "beta : 94 %\n",
      "Confusion matrix:\n",
      " [[129  12  26]\n",
      " [ 29  50  91]\n",
      " [  2   6 135]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(100,500,lr)\n",
    "check_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:46<00:00, 32.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000, train accuracy 0.7596067917783735 and loss 14.981344491243362\n",
      "\n",
      "Test accuracy 0.7416666666666667 and loss 7.008434772491455\n",
      "background : 85 %\n",
      "alpha : 62 %\n",
      "beta : 74 %\n",
      "Confusion matrix:\n",
      " [[143  18   6]\n",
      " [ 29 107  34]\n",
      " [  3  34 106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(500,2000,lr*0.1)\n",
    "check_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:15<00:00, 31.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2500, train accuracy 0.7667560321715817 and loss 14.455217361450195\n",
      "\n",
      "Test accuracy 0.7375 and loss 7.002216160297394\n",
      "background : 86 %\n",
      "alpha : 57 %\n",
      "beta : 78 %\n",
      "Confusion matrix:\n",
      " [[144  15   8]\n",
      " [ 32  98  40]\n",
      " [  3  28 112]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(2000,2500,lr*0.01)\n",
    "check_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:16<00:00, 31.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000, train accuracy 0.7658623771224308 and loss 14.251101911067963\n",
      "\n",
      "Test accuracy 0.7375 and loss 7.0137364864349365\n",
      "background : 86 %\n",
      "alpha : 57 %\n",
      "beta : 78 %\n",
      "Confusion matrix:\n",
      " [[144  15   8]\n",
      " [ 32  98  40]\n",
      " [  3  28 112]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(2500,3000,lr*0.001)\n",
    "check_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff17ac50080>]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nq0HadN3Skr4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff17ab55c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_data[500:], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mini_batch(idx, show_beta=False, show_alpha=False, show_back=False):\n",
    "    y_back = my_dataset.background_dataset[idx]\n",
    "    y_beta = my_dataset.beta_dataset[idx]\n",
    "    y_alpha = my_dataset.alpha_dataset[idx]\n",
    "    y_alpha_10p = [y_alpha.max*0.1 for x in y_alpha]\n",
    "    y_alpha_50p = [y_alpha.max*0.5 for x in y_alpha]\n",
    "    y_alpha_90p = [y_alpha.max*0.9 for x in y_alpha]\n",
    "\n",
    "    y_beta_10p = [y_beta.max*0.1 for x in y_beta]\n",
    "    y_beta_50p = [y_beta.max*0.5 for x in y_beta]\n",
    "    y_beta_90p = [y_beta.max*0.9 for x in y_beta]\n",
    "\n",
    "    y_back_10p = [y_back.max*0.1 for x in y_back]\n",
    "    y_back_50p = [y_back.max*0.5 for x in y_back]\n",
    "    y_back_90p = [y_back.max*0.9 for x in y_back]\n",
    "\n",
    "\n",
    "    if show_alpha:\n",
    "        plt.plot(y_alpha, color='green')\n",
    "        plt.plot(y_alpha_10p, color='yellow')\n",
    "        plt.plot(y_alpha_50p, color='yellow')\n",
    "        plt.plot(y_alpha_90p, color='yellow')\n",
    "        plt.title('Alpha')\n",
    "        y_alpha.print_features()\n",
    "\n",
    "    if show_beta:\n",
    "        plt.plot(y_beta, color='red')\n",
    "        plt.plot(y_beta_10p, color='yellow')\n",
    "        plt.plot(y_beta_50p, color='yellow')\n",
    "        plt.plot(y_beta_90p, color='yellow')\n",
    "        plt.title('Beta')\n",
    "        y_beta.print_features()\n",
    "\n",
    "    if show_back:\n",
    "        plt.plot(y_back, color='blue')\n",
    "        plt.plot(y_back_10p, color='yellow')\n",
    "        plt.plot(y_back_50p, color='yellow')\n",
    "        plt.plot(y_back_90p, color='yellow')\n",
    "        plt.title('Background')\n",
    "        y_back.print_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mini_batch(idx ,False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
